# models: coca-model

defaults:
  - _self_
  - criterion: cross-entropy
  # - optimizer: adam

model:
  _target_: coca_pytorch.coca_pytorch.CoCa
  caption_loss_weight: 1. # weight on the autoregressive caption loss
  contrastive_loss_weight: 1. # weight on the contrastive loss between image and text CLS embeddings
  dim: 256 # model dimension
  dim_head: 64 # dimension per attention head
  heads: 8 # number of attention heads
  image_dim: 1024 # image embedding dimension if not the same as model dimensions
  multimodal_depth: 6 # depth of the multimodal transformer
  num_tokens: 20000 # number of text tokens
  return_embedding: true # return the CLIP-like text and image embeddings
  unimodal_depth: 6 # depth of the unimodal transformer

# https://user-images.githubusercontent.com/38570878/270803523-188b1c4d-bfc2-48ac-bd38-e4ee64df92a9.png
optimizer:
  _target_: torch.optim.Adam
  lr: 5e-4
  weight_decay: 0.01
